{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../framework')\n",
    "from NetworkClass import Network\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n"
     ]
    }
   ],
   "source": [
    "model = Network({\n",
    "        \"network\":{\n",
    "            'input_layer': {\n",
    "                \"units\": 784,\n",
    "                \n",
    "                },\n",
    "            'hidden_layer': [{\n",
    "                    \"units\": 400, \n",
    "                    \"type\": \"Linear\"\n",
    "                }, \n",
    "                {\n",
    "                    \"units\": 50, \n",
    "                    \"activation\": \"relu\",\n",
    "                    \"type\": \"Linear\"\n",
    "\n",
    "                }],\n",
    "            'output_layer': {\n",
    "                \"units\": 10,\n",
    "                \"activation\": \"softmax\",\n",
    "                \"type\": \"Linear\"\n",
    "                }\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([400, 784])\n",
      "Layer 1 , Parameters: torch.Size([400])\n",
      "Layer 2 , Parameters: torch.Size([50, 400])\n",
      "Layer 3 , Parameters: torch.Size([50])\n",
      "Layer 4 , Parameters: torch.Size([10, 50])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for (layer, param) in enumerate(model.parameters()):\n",
    "    print(\"Layer {} , Parameters: {}\".format(layer, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "n_epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size):\n",
    "        self.new_size = new_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return torch.reshape(img, self.new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)), ReshapeTransform((-1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)), ReshapeTransform((-1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(6):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mod, optim, epoch):\n",
    "  mod.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optim.zero_grad()\n",
    "    output = mod(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(mod):\n",
    "  mod.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = mod(data)\n",
    "      test_loss += criterion(output, target).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../framework/NetworkClass.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.activation_scheme[-1](self.output_layer(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0023, Accuracy: 1050/10000 (10%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303813\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.304475\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.301690\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.302385\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.302291\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.304765\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.302037\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.302149\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.300439\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.299417\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.301574\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.300016\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.299546\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.299361\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.302209\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.297662\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.300497\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.296798\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.296965\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.298595\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.297470\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.299166\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.294027\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.296334\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.296450\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.298318\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.292311\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.297567\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.292732\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.294284\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.294344\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.288908\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.294016\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.287612\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.287410\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.289739\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.290546\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.289924\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.282521\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.286258\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.284838\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.284492\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.283417\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.289940\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.276528\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.284971\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.289004\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.275836\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.280585\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.276348\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.268510\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.277176\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.273012\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.281397\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.273507\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.273235\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.271262\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.254057\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.266241\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.263062\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.261558\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.245812\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.257517\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.255754\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.255335\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.244423\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.271855\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.246194\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.242117\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.228163\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.213653\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.230182\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.266505\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.250620\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.245325\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.195682\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.178551\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.215778\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.229548\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.194012\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.212485\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.174382\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.220629\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 2.204746\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.161987\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.153617\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.176678\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.210889\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.192266\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.153674\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.175851\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.118006\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.175491\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.111272\n",
      "\n",
      "Test set: Avg. loss: 0.0021, Accuracy: 4473/10000 (45%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.155629\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.135899\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.136820\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.147595\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.117935\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.162401\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.083035\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.096242\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.141483\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.084950\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.121619\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.047970\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.037539\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.084098\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 2.061252\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 2.137626\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.110131\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.099180\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.077303\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.048139\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.091279\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 2.025969\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 2.032459\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 2.029818\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 2.054635\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.054717\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 2.057983\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.983090\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.981978\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 2.061055\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.958300\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 2.088502\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.985076\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.954911\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.968909\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 2.012296\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.986849\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.995267\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.951802\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.956829\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.952634\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.953299\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.953357\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 2.004437\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.864370\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.989235\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.975495\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.878619\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.980523\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.910388\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.959481\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.932905\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.904046\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.949976\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.972702\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.932121\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.883184\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.951617\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.895764\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 2.055857\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.847556\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.958530\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.973219\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 2.033037\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.942860\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.923839\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.943808\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.889811\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.975438\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.874474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.873286\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.919390\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.921473\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.939413\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.869085\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.843346\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.927297\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.973478\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.882620\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.935391\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.847423\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.944805\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.873208\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 1.924439\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.825551\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.985650\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.879861\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.937792\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.847931\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.857603\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.892263\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.900900\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.839415\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.867611\n",
      "\n",
      "Test set: Avg. loss: 0.0019, Accuracy: 6220/10000 (62%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.867665\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.855525\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.934752\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.835138\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.914364\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.890275\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.836792\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.776846\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.874984\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.857419\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.881353\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.830277\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.844745\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.859720\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.868590\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.831147\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.793768\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.751055\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.844108\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.840216\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.766920\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.794235\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.822090\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.766927\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.756462\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.754897\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.887600\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.784827\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.868952\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.806513\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.843574\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.788580\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.810292\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.834118\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.770197\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.654871\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.756972\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 1.801757\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.844702\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.820140\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.779376\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.759922\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.833854\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.826071\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.774359\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.833662\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.812447\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.779223\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.714514\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.697996\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.744843\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.724391\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.842689\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.712194\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.774168\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.785921\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.791570\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.692574\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.758213\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.833127\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.755536\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.751099\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.802761\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.768570\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.708672\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.794419\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.775762\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 1.684372\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.762844\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.824847\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.800185\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.820103\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.680627\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.810944\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.736237\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.764704\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.800948\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.698475\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.760537\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.786868\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.711409\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 1.770651\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.846521\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 1.729607\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.837593\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.760608\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.731429\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.674649\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.855713\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.678937\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.764310\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.687422\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.766309\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.740261\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 7492/10000 (75%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model)\n",
    "\n",
    "# Pruning every 3 epochs\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(model, optimizer, epoch)\n",
    "  test(model)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([400, 784])\n",
      "Layer 1 , Parameters: torch.Size([400])\n",
      "Layer 2 , Parameters: torch.Size([50, 400])\n",
      "Layer 3 , Parameters: torch.Size([50])\n",
      "Layer 4 , Parameters: torch.Size([10, 50])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_neurons(nn_model):\n",
    "    print(\"Pre-Pruning/n\")\n",
    "    for (layer, param) in enumerate(nn_model.parameters()):\n",
    "        print(\"Layer {} , Parameters: {}\".format(layer, param.shape))    \n",
    "    neurons_to_prune = []\n",
    "    for p in nn_model.parameters():\n",
    "            if len(p.data.size()) != 1:\n",
    "                normed_weights = p.data.abs()\n",
    "                l1_norm_layer = []\n",
    "                for neuron_idx in range(normed_weights.shape[0]):\n",
    "                    l1_norm_layer.append(torch.sum(normed_weights[neuron_idx, :]).item())\n",
    "                neurons_to_prune.append(torch.argmin(torch.FloatTensor(l1_norm_layer)))\n",
    "                neurons_to_prune.append(torch.argmin(torch.FloatTensor(l1_norm_layer)))\n",
    "\n",
    "\n",
    "    param_list = list(nn_model.parameters())\n",
    "    for i, neuron_idx in enumerate(neurons_to_prune):\n",
    "        idx_weights = param_list[i]\n",
    "        if i < len(param_list) - 2:\n",
    "            y = torch.cat((idx_weights[0:neuron_idx], idx_weights[neuron_idx+1:]))\n",
    "            if i > 1 and len(idx_weights.shape) > 1:\n",
    "\n",
    "                y = torch.cat((y[:, 0:neuron_idx-1], y[:, neuron_idx:]), axis=1)\n",
    "        elif i > 1 and len(idx_weights.shape) > 1:\n",
    "            y = torch.cat((idx_weights[:, 0:neuron_idx-1], idx_weights[:, neuron_idx:]), axis=1)\n",
    "        else:\n",
    "            y = idx_weights\n",
    "        idx_weights.data = y  \n",
    "       \n",
    "    print(\"Post Pruning /n\")\n",
    "    for (layer, param) in enumerate(nn_model.parameters()):\n",
    "        print(\"Layer {} , Parameters: {}\".format(layer, param.shape))   \n",
    "        \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([399, 784])\n",
      "Layer 1 , Parameters: torch.Size([399])\n",
      "Layer 2 , Parameters: torch.Size([49, 399])\n",
      "Layer 3 , Parameters: torch.Size([49])\n",
      "Layer 4 , Parameters: torch.Size([10, 49])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0166, -0.0226, -0.0272,  ...,  0.0007,  0.0326,  0.0082],\n",
       "        [-0.0242, -0.0241, -0.0240,  ..., -0.0253, -0.0246,  0.0143],\n",
       "        [-0.0166, -0.0213,  0.0067,  ...,  0.0309, -0.0081, -0.0047],\n",
       "        ...,\n",
       "        [-0.0211, -0.0347, -0.0168,  ..., -0.0312, -0.0197, -0.0021],\n",
       "        [ 0.0035, -0.0318,  0.0043,  ...,  0.0283, -0.0242,  0.0234],\n",
       "        [ 0.0329,  0.0300,  0.0072,  ..., -0.0275, -0.0193, -0.0343]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['input_layer.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n"
     ]
    }
   ],
   "source": [
    "updated_model =  Network({\n",
    "        \"network\":{\n",
    "            'input_layer': {\n",
    "                \"units\": 784,\n",
    "                \n",
    "                },\n",
    "            'hidden_layer': [{\n",
    "                    \"units\": 399, \n",
    "                    \"type\": \"Linear\"\n",
    "                }, \n",
    "                {\n",
    "                    \"units\": 49, \n",
    "                    \"activation\": \"relu\",\n",
    "                    \"type\": \"Linear\"\n",
    "\n",
    "                }],\n",
    "            'output_layer': {\n",
    "                \"units\": 10,\n",
    "                \"activation\": \"softmax\",\n",
    "                \"type\": \"Linear\"\n",
    "                }\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model.load_state_dict(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0166, -0.0226, -0.0272,  ...,  0.0007,  0.0326,  0.0082],\n",
       "         [-0.0242, -0.0241, -0.0240,  ..., -0.0253, -0.0246,  0.0143],\n",
       "         [-0.0166, -0.0213,  0.0067,  ...,  0.0309, -0.0081, -0.0047],\n",
       "         ...,\n",
       "         [-0.0211, -0.0347, -0.0168,  ..., -0.0312, -0.0197, -0.0021],\n",
       "         [ 0.0035, -0.0318,  0.0043,  ...,  0.0283, -0.0242,  0.0234],\n",
       "         [ 0.0329,  0.0300,  0.0072,  ..., -0.0275, -0.0193, -0.0343]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0280,  0.0296,  0.0370, -0.0279,  0.0030,  0.0288,  0.0099, -0.0033,\n",
       "          0.0372,  0.0282, -0.0069, -0.0379, -0.0207,  0.0043, -0.0186, -0.0329,\n",
       "         -0.0096, -0.0285,  0.0250,  0.0132,  0.0359, -0.0307, -0.0269,  0.0046,\n",
       "         -0.0181,  0.0319, -0.0270,  0.0178, -0.0002,  0.0338,  0.0021,  0.0095,\n",
       "          0.0130,  0.0079, -0.0198,  0.0141,  0.0251, -0.0061,  0.0082, -0.0124,\n",
       "          0.0227, -0.0033,  0.0189,  0.0100, -0.0321,  0.0261,  0.0133,  0.0337,\n",
       "          0.0117, -0.0015, -0.0156,  0.0060,  0.0246,  0.0355, -0.0170,  0.0191,\n",
       "         -0.0223,  0.0272,  0.0101, -0.0264,  0.0161,  0.0213,  0.0256,  0.0287,\n",
       "         -0.0242,  0.0012, -0.0019, -0.0252, -0.0202,  0.0225, -0.0318, -0.0191,\n",
       "          0.0406,  0.0061, -0.0289, -0.0275,  0.0047,  0.0203, -0.0364, -0.0343,\n",
       "          0.0124, -0.0154,  0.0284,  0.0242,  0.0344, -0.0049, -0.0201,  0.0004,\n",
       "          0.0156,  0.0339,  0.0146, -0.0138,  0.0134,  0.0065,  0.0094, -0.0051,\n",
       "          0.0079, -0.0043,  0.0355,  0.0346,  0.0019, -0.0107,  0.0030, -0.0259,\n",
       "         -0.0177,  0.0293,  0.0310, -0.0197, -0.0319,  0.0337,  0.0095,  0.0329,\n",
       "         -0.0065,  0.0115, -0.0189, -0.0269, -0.0036, -0.0272, -0.0244, -0.0295,\n",
       "          0.0047, -0.0279,  0.0336,  0.0364,  0.0325, -0.0215,  0.0314, -0.0006,\n",
       "         -0.0046,  0.0212, -0.0232,  0.0330,  0.0197, -0.0057,  0.0229,  0.0338,\n",
       "         -0.0266, -0.0147,  0.0358,  0.0037,  0.0200, -0.0218, -0.0041, -0.0164,\n",
       "          0.0150,  0.0185,  0.0121, -0.0176, -0.0308,  0.0111, -0.0206,  0.0358,\n",
       "         -0.0210, -0.0292, -0.0207,  0.0043,  0.0081, -0.0088,  0.0098, -0.0007,\n",
       "         -0.0301, -0.0227,  0.0241,  0.0343, -0.0128,  0.0042, -0.0326, -0.0113,\n",
       "          0.0114, -0.0082, -0.0181,  0.0329, -0.0224, -0.0180, -0.0159,  0.0151,\n",
       "          0.0161, -0.0137,  0.0054,  0.0360,  0.0129, -0.0197, -0.0285,  0.0107,\n",
       "         -0.0116,  0.0022, -0.0254, -0.0080, -0.0163,  0.0063, -0.0220,  0.0203,\n",
       "         -0.0154, -0.0245,  0.0356, -0.0257,  0.0167, -0.0060, -0.0038, -0.0093,\n",
       "         -0.0326,  0.0364, -0.0022,  0.0002, -0.0286,  0.0124,  0.0084, -0.0150,\n",
       "         -0.0043, -0.0015, -0.0314,  0.0373,  0.0164,  0.0043,  0.0331, -0.0107,\n",
       "         -0.0113,  0.0188,  0.0128, -0.0281,  0.0196, -0.0030, -0.0128, -0.0009,\n",
       "          0.0216,  0.0003, -0.0016, -0.0157,  0.0142,  0.0027, -0.0223,  0.0080,\n",
       "          0.0142,  0.0175, -0.0123,  0.0147,  0.0223,  0.0042,  0.0111,  0.0011,\n",
       "          0.0347,  0.0348, -0.0216,  0.0307,  0.0352,  0.0271,  0.0036, -0.0267,\n",
       "          0.0200,  0.0106,  0.0241,  0.0324, -0.0285, -0.0097,  0.0289, -0.0047,\n",
       "         -0.0106,  0.0158,  0.0328, -0.0047, -0.0207,  0.0272,  0.0124,  0.0197,\n",
       "          0.0093, -0.0044, -0.0038,  0.0121,  0.0213, -0.0208,  0.0113, -0.0138,\n",
       "          0.0173, -0.0306,  0.0326, -0.0234,  0.0220, -0.0100, -0.0317, -0.0298,\n",
       "         -0.0300, -0.0122,  0.0078, -0.0266,  0.0133,  0.0123, -0.0012,  0.0222,\n",
       "         -0.0271, -0.0271,  0.0298, -0.0059, -0.0085, -0.0274,  0.0312,  0.0378,\n",
       "         -0.0276,  0.0362,  0.0203,  0.0072,  0.0008, -0.0041,  0.0225, -0.0054,\n",
       "         -0.0218,  0.0278,  0.0056,  0.0350,  0.0003,  0.0136, -0.0148,  0.0416,\n",
       "          0.0186,  0.0384, -0.0271,  0.0048, -0.0031, -0.0168,  0.0164,  0.0254,\n",
       "         -0.0081,  0.0025,  0.0228,  0.0111, -0.0139, -0.0311, -0.0122,  0.0370,\n",
       "          0.0049,  0.0334, -0.0213, -0.0080, -0.0208, -0.0312,  0.0229, -0.0216,\n",
       "          0.0001, -0.0320,  0.0051, -0.0178, -0.0307,  0.0228,  0.0090, -0.0230,\n",
       "          0.0059,  0.0050, -0.0237, -0.0335, -0.0340,  0.0113, -0.0161,  0.0179,\n",
       "         -0.0066, -0.0127, -0.0205,  0.0120, -0.0125,  0.0302,  0.0432,  0.0060,\n",
       "          0.0013, -0.0323,  0.0113,  0.0003,  0.0004,  0.0226, -0.0039,  0.0093,\n",
       "         -0.0008,  0.0047, -0.0150, -0.0100,  0.0353,  0.0187, -0.0018,  0.0194,\n",
       "          0.0054,  0.0253, -0.0006, -0.0177,  0.0188, -0.0103, -0.0256, -0.0210,\n",
       "         -0.0190,  0.0055, -0.0146, -0.0100, -0.0008, -0.0091, -0.0221,  0.0127,\n",
       "         -0.0275, -0.0186,  0.0146, -0.0219,  0.0142,  0.0054,  0.0291],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.0067,  0.0316,  0.0215,  ...,  0.0331,  0.0067,  0.0010],\n",
       "         [-0.0141,  0.0422,  0.0216,  ..., -0.0269,  0.0267, -0.0078],\n",
       "         [-0.0392,  0.0213,  0.0091,  ...,  0.0211,  0.0151,  0.0420],\n",
       "         ...,\n",
       "         [-0.0320, -0.0379,  0.0230,  ...,  0.0323,  0.0196,  0.0250],\n",
       "         [-0.0054, -0.0024,  0.0545,  ...,  0.0441, -0.0299, -0.0382],\n",
       "         [ 0.0451, -0.0172, -0.0146,  ...,  0.0145, -0.0162, -0.0501]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0077, -0.0100, -0.0172, -0.0126,  0.0416, -0.0083, -0.0176,  0.0341,\n",
       "          0.0057,  0.0094, -0.0356, -0.0029,  0.0212,  0.0490,  0.0292,  0.0064,\n",
       "          0.0545, -0.0287, -0.0056,  0.0262,  0.0210, -0.0005, -0.0280,  0.0211,\n",
       "          0.0160, -0.0023, -0.0191, -0.0015,  0.0154, -0.0107, -0.0225,  0.0452,\n",
       "          0.0015, -0.0084, -0.0396, -0.0136, -0.0032, -0.0154,  0.0248, -0.0245,\n",
       "          0.0295,  0.0123, -0.0086,  0.0407,  0.0263, -0.0280, -0.0200, -0.0078,\n",
       "         -0.0215], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.1613, -0.1551, -0.1406, -0.0604, -0.1378,  0.1700,  0.1270,  0.0634,\n",
       "          -0.0130, -0.1648, -0.0610, -0.1361, -0.1627,  0.1572, -0.1589, -0.1457,\n",
       "           0.1071, -0.0906,  0.2622,  0.2030, -0.0578,  0.2846,  0.2685, -0.1289,\n",
       "          -0.2246, -0.0358,  0.0140,  0.2535, -0.0406, -0.1485,  0.0762, -0.1505,\n",
       "           0.0698, -0.2079,  0.0472,  0.1388,  0.0522,  0.0783,  0.1158,  0.1541,\n",
       "           0.2690, -0.0466, -0.1418,  0.1769, -0.2024,  0.1844, -0.1959,  0.0404,\n",
       "          -0.0923],\n",
       "         [-0.1574, -0.0074, -0.0292, -0.1171,  0.1347, -0.2168,  0.0357, -0.1601,\n",
       "           0.0661, -0.2090, -0.1951,  0.0907,  0.2664,  0.1018, -0.0240,  0.1527,\n",
       "           0.1274,  0.0250,  0.0563, -0.0019, -0.0418, -0.2631,  0.0628, -0.1228,\n",
       "           0.0622, -0.1359,  0.0822, -0.0031, -0.0027, -0.0906, -0.0084,  0.2567,\n",
       "          -0.1841,  0.2131,  0.2033,  0.1352, -0.2101, -0.0384,  0.0307,  0.2086,\n",
       "          -0.1580, -0.1084,  0.3385, -0.0804, -0.1058, -0.0372,  0.1569,  0.2831,\n",
       "           0.0894],\n",
       "         [ 0.1383, -0.0787, -0.1349, -0.0195, -0.0994,  0.0029, -0.1370,  0.2221,\n",
       "          -0.0140, -0.1560, -0.0534,  0.0951,  0.1883,  0.0769, -0.1237,  0.1905,\n",
       "          -0.0910,  0.1503, -0.0777, -0.0523,  0.0740, -0.0277,  0.1321,  0.0042,\n",
       "          -0.0285,  0.1254,  0.0906, -0.1767, -0.0898,  0.2068,  0.0009,  0.1336,\n",
       "          -0.0580,  0.1708,  0.0864, -0.1370, -0.0091, -0.0659, -0.0093,  0.1554,\n",
       "          -0.0027,  0.2190, -0.1432, -0.1271, -0.1688, -0.0272, -0.0866, -0.1931,\n",
       "           0.0666],\n",
       "         [-0.0315,  0.3339, -0.2040, -0.0393,  0.0824, -0.2222,  0.0016,  0.1855,\n",
       "           0.0679, -0.1652, -0.1995,  0.1215,  0.0202,  0.0245,  0.0144, -0.0241,\n",
       "           0.1086,  0.0380, -0.1323,  0.0185, -0.1150,  0.0505,  0.0830, -0.0283,\n",
       "           0.2654, -0.0615, -0.1156,  0.0752,  0.0947,  0.1248, -0.2075, -0.0132,\n",
       "           0.0962,  0.0486, -0.1917,  0.0811,  0.1777, -0.2025, -0.0753,  0.1519,\n",
       "          -0.0062, -0.0202, -0.1939, -0.0921,  0.3086,  0.2315, -0.2132,  0.1600,\n",
       "           0.0568],\n",
       "         [-0.1790,  0.0383,  0.1715,  0.1899, -0.1717,  0.1850, -0.1200,  0.0337,\n",
       "          -0.1300,  0.3306, -0.1510, -0.0524,  0.0414, -0.1493,  0.0293, -0.1625,\n",
       "          -0.0016,  0.1366, -0.0498, -0.2716,  0.1035, -0.2731, -0.0881,  0.0220,\n",
       "           0.0468, -0.0361, -0.0905,  0.1161, -0.0216,  0.1124,  0.0954,  0.1163,\n",
       "          -0.0069, -0.1846, -0.1063,  0.2167, -0.2686,  0.1701,  0.0455, -0.1477,\n",
       "           0.1255, -0.0188,  0.0994,  0.2310,  0.1812, -0.1162,  0.1250,  0.0230,\n",
       "          -0.1361],\n",
       "         [ 0.0418,  0.0582,  0.0242,  0.0010, -0.1368, -0.0718,  0.0063,  0.1238,\n",
       "          -0.1405,  0.0786,  0.0341,  0.0381, -0.0964, -0.0093,  0.0300, -0.1035,\n",
       "           0.1183, -0.1096, -0.0219, -0.1044,  0.1194, -0.0504, -0.0391,  0.0395,\n",
       "           0.0575, -0.0984, -0.1431,  0.0412, -0.1259,  0.1097, -0.0906, -0.1119,\n",
       "           0.0644, -0.0639, -0.0734, -0.1055,  0.1473,  0.0216,  0.0490,  0.0096,\n",
       "          -0.0735,  0.0517, -0.0143, -0.0710, -0.0970,  0.0605, -0.1140, -0.1259,\n",
       "           0.1229],\n",
       "         [-0.0493, -0.0126,  0.0664,  0.0636, -0.1700,  0.0703,  0.0218,  0.1644,\n",
       "           0.0229,  0.1156,  0.2221, -0.0804, -0.0207,  0.1872, -0.0638, -0.0926,\n",
       "           0.0389, -0.0614, -0.0299,  0.1766,  0.0891, -0.2049, -0.0296, -0.2203,\n",
       "          -0.0782,  0.1025,  0.0378,  0.1736,  0.0807,  0.0548,  0.2140,  0.1481,\n",
       "          -0.0375, -0.1166, -0.0384, -0.1409,  0.0965,  0.0847,  0.1472, -0.1558,\n",
       "          -0.1510,  0.1257, -0.1440,  0.0357, -0.1453,  0.0718,  0.1456, -0.0624,\n",
       "           0.0752],\n",
       "         [ 0.2912, -0.0431,  0.2715,  0.2157, -0.0983, -0.0067, -0.0600, -0.1568,\n",
       "           0.0680, -0.0076,  0.1055, -0.1354, -0.0996, -0.0858, -0.0333,  0.0566,\n",
       "           0.0951,  0.0470,  0.0608,  0.1436,  0.0166,  0.2024,  0.0376,  0.3050,\n",
       "          -0.0268,  0.1897, -0.0156, -0.1328,  0.0428, -0.1565, -0.1590, -0.1922,\n",
       "          -0.1959,  0.0446, -0.1298,  0.2285,  0.0291, -0.1021,  0.0005, -0.1574,\n",
       "          -0.0391, -0.1430,  0.2119,  0.1401,  0.1802,  0.1333, -0.1505,  0.1007,\n",
       "          -0.0165],\n",
       "         [-0.2132, -0.1735,  0.0074,  0.1143,  0.1238,  0.1287, -0.1582, -0.1606,\n",
       "           0.0954,  0.0915, -0.0431,  0.0567,  0.2081, -0.1318,  0.1988, -0.0141,\n",
       "           0.0028,  0.0371,  0.0123,  0.0403,  0.0842,  0.0562,  0.0917, -0.1205,\n",
       "           0.1872, -0.0413, -0.0521, -0.1490, -0.0831,  0.1656, -0.0983, -0.1406,\n",
       "           0.2965,  0.1258, -0.1855, -0.1908,  0.1885, -0.0699, -0.1038, -0.1966,\n",
       "          -0.0315,  0.1028,  0.1524, -0.0707, -0.0030, -0.1930,  0.2465, -0.1307,\n",
       "          -0.0785],\n",
       "         [ 0.1464, -0.0767, -0.0991,  0.0880, -0.1096, -0.1058, -0.0420,  0.0687,\n",
       "           0.0874, -0.0085,  0.1402,  0.0808, -0.0683, -0.0759,  0.0426,  0.0650,\n",
       "          -0.1333, -0.0933,  0.0849, -0.0958,  0.0138, -0.1503, -0.1549, -0.0508,\n",
       "          -0.0675, -0.1109, -0.0861, -0.1161, -0.1101, -0.0464,  0.0826,  0.0879,\n",
       "          -0.1047, -0.1295, -0.1632,  0.1227,  0.1364,  0.0912,  0.1326, -0.1158,\n",
       "          -0.0842,  0.1286,  0.0418, -0.0403,  0.0585, -0.1388, -0.0904,  0.0601,\n",
       "          -0.1193]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0812, -0.0687,  0.0897,  0.0273,  0.0311, -0.0934, -0.0782,  0.0742,\n",
       "         -0.1252,  0.1244], requires_grad=True)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(updated_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "updated_optimizer = torch.optim.SGD(updated_model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_optimizer.load_state_dict(optimizer.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {},\n",
       " 'param_groups': [{'lr': 0.01,\n",
       "   'momentum': 0,\n",
       "   'dampening': 0,\n",
       "   'weight_decay': 0,\n",
       "   'nesterov': False,\n",
       "   'params': [140229386518248,\n",
       "    140229386518320,\n",
       "    140229386518392,\n",
       "    140229386518464,\n",
       "    140229386584136,\n",
       "    140229386584208]}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0022, Accuracy: 1449/10000 (14%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(updated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.254512\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.237015\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.161748\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.170681\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.117584\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.070418\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.026452\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.015668\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.047256\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.962584\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.009429\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.973021\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.959345\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.937461\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.967013\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.950365\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.916554\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.970335\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.032132\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.902011\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.004199\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.897221\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.858516\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.809969\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.811747\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.883895\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.819854\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.905298\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.849068\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.807312\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.768993\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.763934\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.849694\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.827436\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.899812\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.768774\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.787257\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.718472\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.820215\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.882014\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.825722\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.858252\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.830297\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.702424\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.795596\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.780134\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.756845\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.808814\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.774319\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.687176\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.717673\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.804334\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.775684\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.797487\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.751236\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.775737\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.790758\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.783514\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.750076\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.876216\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.674418\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.814487\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.704290\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.798199\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.841442\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.726496\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.818655\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.786436\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.779429\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.797037\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.652896\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.755881\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.770050\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.638672\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.736889\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.793808\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.680441\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.685504\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.868880\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.731545\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.808702\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.614030\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.739510\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.819631\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.703894\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.815097\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.687265\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.705082\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.676994\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.767059\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.658442\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.756043\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.743487\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.714946\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 7546/10000 (75%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.667161\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.802054\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.757540\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.724539\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.811287\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.779035\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.764864\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.707051\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.698230\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.736098\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.748713\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.761729\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.647915\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.753981\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.760640\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.741636\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.740479\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 1.755600\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.741094\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.697453\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.682691\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.703077\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.815716\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.665317\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.747792\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.810955\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.788287\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.723455\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.733988\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.805865\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.604153\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.740194\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.643427\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.785309\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.757564\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.815248\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.723186\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.738595\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.763711\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.679257\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.736026\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.757893\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.730029\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.704661\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.781867\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.733167\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.705887\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.671207\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.731553\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.741239\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.699074\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.856523\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.790560\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.684154\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.752342\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.698569\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.676203\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.710688\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.692598\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.764606\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.784938\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.731986\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.767821\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.691877\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.727220\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.882752\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.728578\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.663323\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.649068\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.704366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.787203\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.789436\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.723698\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.663345\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.714517\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.763777\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.718567\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.756306\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.691546\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.739796\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.725823\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.670192\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.765046\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 1.750560\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.695944\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.728200\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.706866\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.794380\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.795415\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.751952\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.710233\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.791252\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.685621\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.789904\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 7588/10000 (76%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.625153\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.673239\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.670937\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.673778\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.766052\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.767304\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.664512\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.711550\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.633230\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.781804\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.745359\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.786172\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.744847\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.676812\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.587419\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.675622\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.707345\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.799275\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.669608\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.703919\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.723155\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.755292\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.658862\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.719766\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.676708\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.719009\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.694482\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.718735\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.663585\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.789291\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.689003\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.687739\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.689074\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.748610\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.643231\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.696057\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.717969\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 1.703990\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.752102\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.660104\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.628416\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.753102\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.700408\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.700012\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.747199\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.680731\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.732064\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.680462\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.693839\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.762067\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.609809\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.652421\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.624751\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.658407\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.697632\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.620388\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.724188\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.764003\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.753787\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.628644\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.720088\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.740493\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.750101\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.658021\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.665771\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.710225\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.648758\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 1.693333\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.666259\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.835607\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.692883\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.801283\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.696187\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.762762\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.772839\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.805538\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.655751\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.687318\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.779495\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.721219\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.705986\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 1.677716\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.771994\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 1.672287\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.633867\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.758572\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.693116\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.700163\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.766864\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.596761\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.710410\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.634974\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.684110\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.661722\n",
      "\n",
      "Test set: Avg. loss: 0.0017, Accuracy: 7630/10000 (76%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pruning every 3 epochs\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(updated_model, updated_optimizer, epoch)\n",
    "  test(updated_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

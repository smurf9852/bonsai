{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../framework')\n",
    "from NetworkClass import Network\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n"
     ]
    }
   ],
   "source": [
    "model = Network({\n",
    "        \"network\":{\n",
    "            'input_layer': {\n",
    "                \"units\": 784,\n",
    "                \n",
    "                },\n",
    "            'hidden_layer': [{\n",
    "                    \"units\": 400, \n",
    "                    \"type\": \"Linear\"\n",
    "                }, \n",
    "                {\n",
    "                    \"units\": 50, \n",
    "                    \"activation\": \"relu\",\n",
    "                    \"type\": \"Linear\"\n",
    "\n",
    "                }],\n",
    "            'output_layer': {\n",
    "                \"units\": 10,\n",
    "                \"activation\": \"softmax\",\n",
    "                \"type\": \"Linear\"\n",
    "                }\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([400, 784])\n",
      "Layer 1 , Parameters: torch.Size([400])\n",
      "Layer 2 , Parameters: torch.Size([50, 400])\n",
      "Layer 3 , Parameters: torch.Size([50])\n",
      "Layer 4 , Parameters: torch.Size([10, 50])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for (layer, param) in enumerate(model.parameters()):\n",
    "    print(\"Layer {} , Parameters: {}\".format(layer, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "n_epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReshapeTransform:\n",
    "    def __init__(self, new_size):\n",
    "        self.new_size = new_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return torch.reshape(img, self.new_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)), ReshapeTransform((-1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('../data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,)), ReshapeTransform((-1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(6):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = model(data)\n",
    "      test_loss += criterion(output, target).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0020, Accuracy: 4168/10000 (42%)\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (399) must match the size of tensor b (397) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-8986215e1fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Pruning every 3 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-90-e3fc87f59438>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (399) must match the size of tensor b (397) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "test()\n",
    "\n",
    "# Pruning every 3 epochs\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([399, 784])\n",
      "Layer 1 , Parameters: torch.Size([399])\n",
      "Layer 2 , Parameters: torch.Size([49, 399])\n",
      "Layer 3 , Parameters: torch.Size([49])\n",
      "Layer 4 , Parameters: torch.Size([10, 49])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for (layer, param) in enumerate(model.parameters()):\n",
    "    print(\"Layer {} , Parameters: {}\".format(layer, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_to_prune = []\n",
    "for p in model.parameters():\n",
    "        if len(p.data.size()) != 1:\n",
    "            normed_weights = p.data.abs()\n",
    "            l1_norm_layer = []\n",
    "            for neuron_idx in range(normed_weights.shape[0]):\n",
    "                l1_norm_layer.append(torch.sum(normed_weights[neuron_idx, :]).item())\n",
    "            neurons_to_prune.append(torch.argmin(torch.FloatTensor(l1_norm_layer)))\n",
    "            neurons_to_prune.append(torch.argmin(torch.FloatTensor(l1_norm_layer)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 3.1660e-02, -1.8102e-02,  4.2061e-03,  ...,  1.7766e-02,\n",
       "          -3.1633e-04, -1.8067e-02],\n",
       "         [-2.5592e-02,  2.2755e-02,  1.2970e-03,  ..., -1.2253e-02,\n",
       "          -3.2247e-02,  2.5801e-02],\n",
       "         [-9.1272e-03, -2.3506e-02,  8.0663e-03,  ..., -2.2597e-02,\n",
       "           2.9777e-02,  1.8771e-03],\n",
       "         ...,\n",
       "         [ 5.9019e-04, -2.4208e-02,  3.1661e-02,  ..., -6.7178e-03,\n",
       "          -7.4413e-03, -7.8642e-03],\n",
       "         [ 4.3384e-05,  1.8712e-03,  9.2949e-03,  ...,  2.0801e-03,\n",
       "          -2.5955e-02,  2.3680e-02],\n",
       "         [ 1.5148e-02, -2.0020e-02,  3.1257e-02,  ..., -1.9081e-02,\n",
       "          -1.4316e-02, -1.8939e-02]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0196, -0.0180,  0.0159,  0.0038, -0.0150,  0.0293,  0.0356,  0.0246,\n",
       "         -0.0261, -0.0162,  0.0278,  0.0214, -0.0156, -0.0144, -0.0240, -0.0031,\n",
       "         -0.0182,  0.0287, -0.0281, -0.0090,  0.0309, -0.0089, -0.0104, -0.0102,\n",
       "          0.0375, -0.0281,  0.0305, -0.0198, -0.0218,  0.0239,  0.0269,  0.0055,\n",
       "          0.0323, -0.0126, -0.0092, -0.0213,  0.0115,  0.0139, -0.0180,  0.0139,\n",
       "          0.0377,  0.0190,  0.0340, -0.0332, -0.0070, -0.0309, -0.0127,  0.0237,\n",
       "         -0.0256, -0.0089,  0.0262, -0.0046, -0.0057,  0.0075, -0.0108, -0.0062,\n",
       "          0.0158,  0.0079,  0.0072, -0.0182, -0.0063,  0.0399,  0.0190,  0.0336,\n",
       "         -0.0198,  0.0304, -0.0208, -0.0106,  0.0094,  0.0245,  0.0170,  0.0330,\n",
       "         -0.0161, -0.0068, -0.0052,  0.0172,  0.0110,  0.0196, -0.0291, -0.0138,\n",
       "          0.0352, -0.0233, -0.0130,  0.0021, -0.0307,  0.0116, -0.0087,  0.0350,\n",
       "         -0.0211,  0.0178,  0.0316, -0.0078,  0.0394,  0.0092,  0.0243, -0.0035,\n",
       "         -0.0133, -0.0253,  0.0067,  0.0235,  0.0058, -0.0140,  0.0035, -0.0034,\n",
       "         -0.0284,  0.0190,  0.0187,  0.0202,  0.0014,  0.0358,  0.0069, -0.0203,\n",
       "          0.0030,  0.0089,  0.0323,  0.0117, -0.0207,  0.0346,  0.0236, -0.0215,\n",
       "          0.0123,  0.0222, -0.0223,  0.0342, -0.0002,  0.0340,  0.0064,  0.0200,\n",
       "          0.0085,  0.0205,  0.0071,  0.0021,  0.0103, -0.0204, -0.0243,  0.0206,\n",
       "         -0.0200,  0.0032, -0.0290, -0.0245,  0.0198,  0.0068, -0.0032, -0.0040,\n",
       "         -0.0010, -0.0029, -0.0014, -0.0252,  0.0435,  0.0356,  0.0208, -0.0004,\n",
       "          0.0025,  0.0054,  0.0394,  0.0040,  0.0193,  0.0097,  0.0338, -0.0232,\n",
       "          0.0039, -0.0203,  0.0157,  0.0159,  0.0089, -0.0253,  0.0139, -0.0054,\n",
       "          0.0087,  0.0164, -0.0204, -0.0121, -0.0201,  0.0172,  0.0143,  0.0093,\n",
       "          0.0301,  0.0330,  0.0093, -0.0157, -0.0118,  0.0271,  0.0157, -0.0124,\n",
       "          0.0327, -0.0028,  0.0094, -0.0090, -0.0178,  0.0362,  0.0314, -0.0151,\n",
       "          0.0114,  0.0321, -0.0106,  0.0007, -0.0005,  0.0393,  0.0225,  0.0162,\n",
       "         -0.0106, -0.0086,  0.0163,  0.0006, -0.0200,  0.0069,  0.0037, -0.0057,\n",
       "         -0.0148, -0.0137, -0.0268, -0.0151, -0.0029, -0.0193, -0.0073, -0.0311,\n",
       "          0.0313, -0.0012,  0.0177,  0.0306,  0.0188,  0.0102,  0.0163,  0.0170,\n",
       "         -0.0227,  0.0372,  0.0173,  0.0154, -0.0240, -0.0130,  0.0081, -0.0235,\n",
       "          0.0139,  0.0117, -0.0335,  0.0209, -0.0159, -0.0114,  0.0319, -0.0285,\n",
       "          0.0158,  0.0371, -0.0071, -0.0312,  0.0291, -0.0174, -0.0206,  0.0082,\n",
       "         -0.0038, -0.0240, -0.0130,  0.0299,  0.0052, -0.0251,  0.0329, -0.0164,\n",
       "         -0.0136,  0.0335,  0.0232, -0.0129, -0.0257,  0.0398,  0.0014,  0.0203,\n",
       "          0.0111, -0.0182, -0.0180,  0.0168, -0.0043,  0.0203, -0.0144, -0.0027,\n",
       "         -0.0141, -0.0270,  0.0025,  0.0382,  0.0226, -0.0022, -0.0285, -0.0051,\n",
       "          0.0034,  0.0202,  0.0081,  0.0294,  0.0303,  0.0397,  0.0071, -0.0221,\n",
       "         -0.0002,  0.0187,  0.0266, -0.0136,  0.0116,  0.0057,  0.0087,  0.0113,\n",
       "         -0.0301, -0.0008, -0.0179,  0.0296, -0.0053, -0.0273, -0.0102,  0.0427,\n",
       "         -0.0176, -0.0070, -0.0219, -0.0134,  0.0201, -0.0248,  0.0387,  0.0283,\n",
       "         -0.0281, -0.0253, -0.0283,  0.0200, -0.0012,  0.0290, -0.0079, -0.0214,\n",
       "          0.0013,  0.0314,  0.0340,  0.0126, -0.0274,  0.0320,  0.0143, -0.0288,\n",
       "         -0.0275,  0.0313, -0.0178,  0.0319,  0.0156,  0.0002, -0.0174,  0.0094,\n",
       "         -0.0187, -0.0030,  0.0099,  0.0309, -0.0263, -0.0126, -0.0300, -0.0101,\n",
       "          0.0134, -0.0268, -0.0029,  0.0163, -0.0106,  0.0260,  0.0017, -0.0003,\n",
       "          0.0176, -0.0002,  0.0063, -0.0204, -0.0042,  0.0152,  0.0159, -0.0226,\n",
       "          0.0193, -0.0178, -0.0055, -0.0140, -0.0157, -0.0028,  0.0387, -0.0197,\n",
       "          0.0375, -0.0103,  0.0178,  0.0256, -0.0201,  0.0171,  0.0035, -0.0056,\n",
       "          0.0013,  0.0017,  0.0142,  0.0350,  0.0077,  0.0095,  0.0118, -0.0286,\n",
       "         -0.0333,  0.0168,  0.0212,  0.0010, -0.0314,  0.0040,  0.0148,  0.0050,\n",
       "         -0.0341,  0.0098, -0.0302,  0.0364, -0.0191, -0.0075,  0.0084],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0361,  0.0296, -0.0116,  ..., -0.0536,  0.0775, -0.0023],\n",
       "         [-0.0140,  0.0296, -0.0275,  ..., -0.0359,  0.0204,  0.0282],\n",
       "         [-0.0425, -0.0447,  0.0142,  ...,  0.0727,  0.0582,  0.0692],\n",
       "         ...,\n",
       "         [ 0.0519,  0.0815, -0.0123,  ..., -0.0470, -0.0272,  0.0203],\n",
       "         [-0.0168,  0.0062,  0.0236,  ..., -0.0059,  0.0225,  0.0245],\n",
       "         [-0.0049, -0.0846,  0.0233,  ...,  0.0570,  0.0310,  0.0044]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0224,  0.0126,  0.0279,  0.0315, -0.0163,  0.0099,  0.0613,  0.0003,\n",
       "          0.0060, -0.0201, -0.0086, -0.0288,  0.0496, -0.0090,  0.0050,  0.0140,\n",
       "         -0.0064,  0.0501,  0.0170, -0.0120, -0.0263, -0.0151,  0.0629,  0.0018,\n",
       "         -0.0153, -0.0121,  0.0164, -0.0072,  0.0643,  0.0514,  0.0340, -0.0366,\n",
       "         -0.0016, -0.0363,  0.0084,  0.0586,  0.0580,  0.0328, -0.0057, -0.0244,\n",
       "         -0.0030,  0.0463,  0.0549,  0.0179,  0.0458, -0.0231, -0.0236,  0.0323,\n",
       "          0.0195], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.7367e-01,  3.9368e-02, -2.4237e-01,  1.9908e-01,  2.6094e-01,\n",
       "          -1.3231e-01,  1.1972e-01,  3.0757e-01,  3.0656e-02, -6.6983e-02,\n",
       "           4.1761e-01,  6.8411e-03, -2.0484e-01,  1.5998e-01,  3.5096e-01,\n",
       "          -3.1035e-02, -3.5272e-02, -6.9608e-02, -1.3528e-01,  2.5686e-02,\n",
       "          -3.9581e-04, -2.2374e-01, -1.8237e-02,  4.0448e-01, -4.8412e-02,\n",
       "          -2.0112e-01, -1.4350e-01,  1.2432e-01,  3.8583e-01, -1.7736e-01,\n",
       "          -9.5563e-02, -1.4551e-01, -8.9147e-02, -2.4465e-01, -2.1023e-01,\n",
       "          -1.9247e-01,  3.9620e-02, -1.0309e-01,  1.2503e-01, -9.3802e-02,\n",
       "          -7.9464e-02, -3.4732e-02, -1.7442e-01, -9.9795e-02, -3.1394e-02,\n",
       "          -8.2379e-02,  2.5839e-01, -9.3103e-02, -3.2857e-02],\n",
       "         [ 1.8382e-01, -2.0304e-01,  6.3567e-02,  3.0073e-02, -3.5203e-01,\n",
       "           1.8936e-02, -1.3215e-01,  1.1287e-01,  3.0197e-01,  1.7629e-01,\n",
       "          -2.8173e-01,  6.0338e-02, -1.9218e-01, -2.1168e-02, -2.8176e-01,\n",
       "          -9.4906e-02, -1.2346e-01,  3.0383e-01,  1.0080e-01,  1.2654e-01,\n",
       "           1.0018e-01,  3.7571e-01,  2.1797e-01, -1.3343e-01,  2.4836e-01,\n",
       "           2.5630e-01, -1.1664e-01, -2.8306e-01, -2.0453e-02, -2.0591e-01,\n",
       "          -1.4774e-01, -2.0510e-01, -2.1885e-01,  1.7669e-01,  6.3329e-02,\n",
       "          -4.5100e-02, -9.8485e-03, -2.0785e-01,  4.1354e-02, -1.7749e-02,\n",
       "           6.3070e-03, -1.1362e-01,  9.7197e-02,  7.7373e-03, -1.5257e-01,\n",
       "          -1.8614e-02, -3.3271e-02,  3.3202e-01,  1.1988e-02],\n",
       "         [-3.8438e-02, -5.4048e-02, -6.5840e-02, -4.6134e-02,  3.6734e-01,\n",
       "          -1.6163e-03,  5.5057e-02, -2.3579e-01,  6.0678e-02,  1.2437e-02,\n",
       "           8.7470e-02, -1.0729e-01, -2.3624e-01,  1.1406e-01, -1.8746e-02,\n",
       "          -6.1163e-02, -6.7120e-02,  3.2527e-02,  2.5600e-01, -1.6499e-01,\n",
       "          -5.2034e-02, -6.4968e-02,  4.3271e-02, -1.0638e-01, -2.2995e-01,\n",
       "           3.2167e-02, -2.5857e-02,  1.2532e-01, -1.1348e-01, -9.6506e-02,\n",
       "           2.7826e-02, -1.0348e-01, -1.9663e-01,  1.0318e-01,  3.8802e-01,\n",
       "           1.6748e-01, -1.4313e-01, -1.3002e-01, -2.2503e-01, -1.6981e-02,\n",
       "           3.4373e-01,  4.5225e-01, -2.2521e-01,  2.3540e-01,  1.1373e-01,\n",
       "           2.4868e-01,  2.1040e-01, -2.0356e-01, -3.2935e-01],\n",
       "         [ 1.5584e-01, -3.3779e-03,  2.6663e-01,  3.1174e-01,  4.5459e-01,\n",
       "          -3.1445e-01,  2.9834e-01, -4.9392e-02, -1.5018e-01,  4.0256e-02,\n",
       "          -2.0580e-01,  7.6421e-02, -2.5538e-01,  1.0380e-01, -3.5767e-02,\n",
       "          -4.6332e-02, -1.0121e-01, -2.7292e-01, -9.7093e-02, -3.5973e-01,\n",
       "           1.0296e-01,  1.1616e-02,  2.0497e-01, -1.2186e-01,  6.1387e-02,\n",
       "           1.1805e-01, -3.4847e-02,  2.6170e-01, -2.0915e-01, -1.5529e-01,\n",
       "           5.6119e-02,  2.9917e-01,  1.6953e-02, -1.7933e-01, -1.6323e-01,\n",
       "           1.8615e-01,  3.4409e-02, -1.7625e-01,  1.6274e-01,  1.2219e-01,\n",
       "          -2.4065e-01, -5.1702e-02,  8.7244e-02,  3.2340e-01,  2.5092e-02,\n",
       "           1.0219e-01, -4.0184e-01,  1.3909e-01,  1.7097e-01],\n",
       "         [-1.4014e-01,  2.1541e-01,  1.5005e-01,  1.9534e-01, -3.6293e-01,\n",
       "           1.5053e-01,  5.0657e-02, -1.9692e-01,  1.1858e-02,  2.1820e-02,\n",
       "          -1.0707e-01,  7.5385e-02,  1.8667e-01, -3.0584e-02, -1.1567e-01,\n",
       "          -1.4505e-01, -3.2070e-02,  3.2323e-02,  3.2075e-02,  9.6253e-02,\n",
       "          -3.2024e-01, -2.3915e-01, -3.9101e-01,  2.1462e-02,  6.6853e-03,\n",
       "          -2.2543e-01, -5.5521e-02, -6.3624e-02,  1.0273e-01,  3.9103e-01,\n",
       "           5.4217e-02, -4.4505e-02,  9.8385e-02, -6.5800e-02, -1.3741e-01,\n",
       "           1.4434e-01,  1.7637e-03,  2.7543e-01, -1.5150e-02,  5.0585e-03,\n",
       "           3.2721e-02, -2.2504e-01,  3.1969e-01, -2.8629e-01,  3.7999e-01,\n",
       "           1.4040e-01,  1.0052e-01,  1.4663e-01,  3.4253e-01],\n",
       "         [-1.4822e-01,  8.6302e-02, -9.1368e-02, -8.8821e-02, -1.0035e-01,\n",
       "           4.5268e-03, -5.1708e-02,  1.7965e-02,  8.6796e-02, -1.0814e-01,\n",
       "          -5.5324e-02,  7.7987e-02,  9.5325e-02, -1.2059e-01,  3.6443e-02,\n",
       "          -3.0961e-02,  6.1452e-02,  1.6509e-02, -8.6145e-02,  1.1133e-01,\n",
       "          -8.4509e-02,  7.7199e-02, -1.4470e-01, -1.0760e-01, -7.9139e-02,\n",
       "           1.0685e-01,  8.3125e-02,  6.3670e-02,  1.4691e-01,  1.6541e-02,\n",
       "          -7.9957e-02,  2.2584e-02, -8.4096e-02, -3.4826e-02, -1.4283e-01,\n",
       "          -1.1577e-01,  5.8135e-02, -2.9383e-02,  3.1540e-02, -7.7822e-02,\n",
       "          -6.9773e-03,  1.0329e-01, -2.8378e-03,  1.5271e-02, -1.0696e-03,\n",
       "           9.0435e-02, -1.1185e-01, -1.3865e-01, -8.9553e-02],\n",
       "         [-1.3093e-01, -1.5447e-01, -3.3276e-01, -1.4845e-01, -1.8886e-01,\n",
       "          -2.3974e-01, -2.9400e-01, -9.0563e-02,  1.8025e-01, -1.1169e-01,\n",
       "          -6.2439e-05,  2.2264e-01,  4.0897e-01,  1.2524e-01, -1.0881e-01,\n",
       "           2.0870e-01,  1.3464e-01, -1.1110e-01,  1.3237e-01,  1.5385e-01,\n",
       "          -2.4570e-01, -6.2751e-02,  3.5526e-01,  8.8841e-02, -1.6524e-01,\n",
       "          -2.4965e-01, -1.5635e-01, -2.6788e-01, -2.1638e-01, -1.0563e-02,\n",
       "          -1.8044e-02, -2.9381e-02,  1.2009e-01,  1.4789e-01,  4.5233e-02,\n",
       "          -1.2569e-01, -3.3806e-02,  3.3803e-01,  4.3761e-02, -4.2432e-02,\n",
       "          -3.2000e-01,  3.0435e-01,  1.3765e-01, -1.3929e-01,  2.8953e-01,\n",
       "          -1.5821e-01,  2.2765e-01,  2.1286e-02, -1.8367e-01],\n",
       "         [-1.8549e-01, -5.3777e-02,  3.2512e-01, -3.0365e-01, -2.1123e-01,\n",
       "           2.7061e-01,  3.7716e-01, -1.8429e-01, -4.6520e-02, -6.0874e-02,\n",
       "           1.3182e-01, -2.8096e-01, -1.8438e-01,  1.1595e-01, -2.1445e-02,\n",
       "           3.0926e-01,  1.8085e-01, -4.9305e-02, -1.4404e-01,  2.4587e-01,\n",
       "           3.4517e-01, -1.3995e-01, -3.1491e-01, -1.8525e-01, -3.2351e-02,\n",
       "           9.0592e-02, -7.5553e-02,  1.9048e-01,  1.1849e-01,  2.1943e-01,\n",
       "           3.0385e-02,  4.2953e-02, -1.3796e-01, -7.7194e-02, -1.4244e-01,\n",
       "          -1.7645e-01,  3.6651e-02, -1.8055e-01,  5.9118e-02, -1.4902e-01,\n",
       "          -7.4734e-02, -2.9463e-01,  1.2350e-01,  3.3298e-01, -2.1725e-01,\n",
       "           2.4941e-01,  1.1662e-01, -1.6206e-02,  3.4922e-02],\n",
       "         [-9.2415e-02,  1.5508e-01,  1.1069e-01, -2.0594e-04,  7.2586e-02,\n",
       "          -8.3665e-02, -1.4593e-01,  2.1936e-01, -3.2815e-02, -1.4057e-01,\n",
       "           2.1317e-01,  1.6656e-01,  2.4252e-01, -1.7537e-01, -2.5176e-02,\n",
       "          -2.4904e-01, -6.4594e-02, -8.0696e-02, -1.2701e-01,  1.8192e-01,\n",
       "           9.9948e-02,  1.0248e-01, -2.1374e-02, -1.3659e-01, -1.7650e-01,\n",
       "          -7.9943e-02,  4.6282e-03,  2.0200e-01,  1.2844e-01,  2.6882e-01,\n",
       "           1.6714e-01,  1.4828e-01,  3.2561e-01,  5.2581e-02,  4.7406e-02,\n",
       "          -6.4741e-02,  2.0412e-02,  8.0408e-02,  1.1644e-01,  3.9910e-02,\n",
       "           3.7986e-01, -1.2845e-01, -3.2899e-01, -2.6410e-01, -3.0303e-01,\n",
       "          -3.3437e-01,  8.5005e-02,  3.5970e-02,  1.0559e-01],\n",
       "         [ 3.9878e-02,  9.9352e-02, -1.0663e-01,  7.3441e-02, -9.8764e-02,\n",
       "           3.0813e-02, -4.4604e-02,  3.9818e-02, -1.1818e-01,  6.0519e-02,\n",
       "          -8.7651e-02, -1.0610e-01,  2.1899e-02,  8.1687e-02, -2.3889e-03,\n",
       "          -3.9072e-02,  3.3393e-02, -1.2757e-01, -5.6298e-02,  4.2136e-02,\n",
       "          -1.4435e-01, -2.7331e-02, -6.3883e-02,  1.0056e-01, -1.4459e-01,\n",
       "           9.0236e-02, -1.4448e-01, -3.9149e-02, -7.0321e-02, -7.9336e-02,\n",
       "           7.3045e-02,  1.0095e-01,  1.8066e-02, -1.0088e-01,  2.8671e-03,\n",
       "          -2.5446e-02, -1.0070e-01, -2.6639e-02,  9.6225e-02,  4.9944e-02,\n",
       "           9.4864e-02, -1.4373e-01, -2.6062e-02,  1.1491e-01,  8.7576e-03,\n",
       "           6.9093e-02, -3.3002e-02, -9.9620e-02, -1.0986e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0855,  0.0132, -0.0248,  0.0056,  0.0423,  0.0898,  0.0860, -0.0600,\n",
       "         -0.1790, -0.1254], requires_grad=True)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = list(model.parameters())\n",
    "for i, neuron_idx in enumerate(neurons_to_prune):\n",
    "    idx_weights = param_list[i]\n",
    "    if i < len(param_list) - 2:\n",
    "        y = torch.cat((idx_weights[0:neuron_idx], idx_weights[neuron_idx+1:]))\n",
    "        if i > 1 and len(idx_weights.shape) > 1:\n",
    "\n",
    "            y = torch.cat((y[:, 0:neuron_idx-1], y[:, neuron_idx:]), axis=1)\n",
    "    elif i > 1 and len(idx_weights.shape) > 1:\n",
    "        y = torch.cat((idx_weights[:, 0:neuron_idx-1], idx_weights[:, neuron_idx:]), axis=1)\n",
    "    else:\n",
    "        y = idx_weights\n",
    "    idx_weights.data = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 , Parameters: torch.Size([397, 784])\n",
      "Layer 1 , Parameters: torch.Size([397])\n",
      "Layer 2 , Parameters: torch.Size([47, 397])\n",
      "Layer 3 , Parameters: torch.Size([47])\n",
      "Layer 4 , Parameters: torch.Size([10, 47])\n",
      "Layer 5 , Parameters: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for (layer, param) in enumerate(model.parameters()):\n",
    "    print(\"Layer {} , Parameters: {}\".format(layer, param.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.1660e-02, -1.8102e-02,  4.2061e-03,  ...,  1.7766e-02,\n",
       "         -3.1633e-04, -1.8067e-02],\n",
       "        [-2.5592e-02,  2.2755e-02,  1.2970e-03,  ..., -1.2253e-02,\n",
       "         -3.2247e-02,  2.5801e-02],\n",
       "        [-9.1272e-03, -2.3506e-02,  8.0663e-03,  ..., -2.2597e-02,\n",
       "          2.9777e-02,  1.8771e-03],\n",
       "        ...,\n",
       "        [ 5.9019e-04, -2.4208e-02,  3.1661e-02,  ..., -6.7178e-03,\n",
       "         -7.4413e-03, -7.8642e-03],\n",
       "        [ 4.3384e-05,  1.8712e-03,  9.2949e-03,  ...,  2.0801e-03,\n",
       "         -2.5955e-02,  2.3680e-02],\n",
       "        [ 1.5148e-02, -2.0020e-02,  3.1257e-02,  ..., -1.9081e-02,\n",
       "         -1.4316e-02, -1.8939e-02]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['input_layer.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax\n"
     ]
    }
   ],
   "source": [
    "updated_model =  Network({\n",
    "        \"network\":{\n",
    "            'input_layer': {\n",
    "                \"units\": 784,\n",
    "                \n",
    "                },\n",
    "            'hidden_layer': [{\n",
    "                    \"units\": 397, \n",
    "                    \"type\": \"Linear\"\n",
    "                }, \n",
    "                {\n",
    "                    \"units\": 47, \n",
    "                    \"activation\": \"relu\",\n",
    "                    \"type\": \"Linear\"\n",
    "\n",
    "                }],\n",
    "            'output_layer': {\n",
    "                \"units\": 10,\n",
    "                \"activation\": \"softmax\",\n",
    "                \"type\": \"Linear\"\n",
    "                }\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_model.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "updated_optimizer = torch.optim.SGD(updated_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_optimizer.load_state_dict(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = updated_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = updated_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (input_layer): Linear(in_features=784, out_features=397, bias=True)\n",
       "  (hidden_layers): ModuleList(\n",
       "    (0): Linear(in_features=397, out_features=47, bias=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=47, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
